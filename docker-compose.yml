services:
  ai-toolkit:
    build:
      context: .
      dockerfile: Dockerfile.ai-toolkit
    image: ai-toolkit:latest
    container_name: ai-toolkit
    working_dir: /app
    ports:
      - ""
    volumes:
      - ./config:/app/config
      - ./workspace:/app/workspace
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    restart: unless-stopped
    stdin_open: true
    tty: true

  # TabbyML - Self-hosted AI coding assistant
  tabbyml:
    image: tabbyml/tabby:latest
    container_name: tabbyml
    command: ["serve", "--model", "StarCoder-1B", "--device", "cpu", "--chat-model", "Qwen2-1.5B-Instruct"]
    ports:
      - ""
    volumes:
      - tabby-data:/data
    restart: unless-stopped

volumes:
  tabby-data:
