# API Keys Configuration
# Copy this file to .env and fill in your actual API keys
# The .env file is ignored by git for security

OPENAI_API_KEY=sk-your-openai-api-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
GEMINI_API_KEY=your-gemini-api-key-here

# Optional: Docker Hub credentials (for private images)
# DOCKER_USERNAME=your-docker-username
# DOCKER_PASSWORD=your-docker-password

# Local inference (PowerInfer - HTTP)
# POWERINFER_HOST=http://localhost:11434
# POWERINFER_MODEL=meta-llama-3-8b-q4

# Local inference (PowerInfer - CLI fallback)
# POWERINFER_CLI=powerinfer --model "C:\\models\\llama3.gguf" --prompt "{prompt}" --n-predict 256

# Local inference (TurboSparse - HTTP)
# TURBOSPARSE_HOST=http://localhost:11435
# TURBOSPARSE_MODEL=meta-llama-3-8b-q4

# Local inference (TurboSparse - CLI fallback)
# TURBOSPARSE_CLI=turbosparse --model "C:\\models\\llama3.gguf" --prompt "{prompt}" --max-tokens 256

